{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4268a875-7eee-44e8-8843-3c972e8b6899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2561dc-9ae8-4ef5-b240-5e498e8109ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple PDFs into a list of documents\n",
    "def load_pdfs(file_paths):\n",
    "    all_docs = []\n",
    "    for file_path in file_paths:\n",
    "        loader = PyMuPDFLoader(file_path=file_path)\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)  # Add documents from each PDF to the combined list\n",
    "    return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939075c9-3446-42ed-b436-f0840c0995f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Responsible for splitting the documents into several chunks\n",
    "def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n",
    "\n",
    "    # Initializing the RecursiveCharacterTextSplitter with\n",
    "    # chunk_size and chunk_overlap\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "\n",
    "    # Splitting the documents into chunks\n",
    "    chunks = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "    # returning the document chunks\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b47eb4-e5cc-409b-a65a-e739f8402a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading the embedding model\n",
    "def load_embedding_model(model_path, normalize_embedding=True):\n",
    "    return HuggingFaceEmbeddings(\n",
    "        model_name=model_path,\n",
    "        model_kwargs={'device':'cpu'}, # here we will run the model with CPU only\n",
    "        encode_kwargs = {\n",
    "            'normalize_embeddings': normalize_embedding # keep True to compute cosine similarity\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b44e283-63a2-4cd6-b641-9515fad35643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating embeddings using FAISS\n",
    "def create_embeddings(chunks, embedding_model, storing_path=\"vectorstore\"):\n",
    "    # Creating the embeddings using FAISS\n",
    "    vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "    # Saving the model in current directory\n",
    "    vectorstore.save_local(storing_path)\n",
    "\n",
    "    # returning the vectorstore\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9cfe1f-40c0-45e8-a91c-425735b25e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the chain for Question Answering\n",
    "def load_qa_chain(retriever, llm, prompt):\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever, # here we are using the vectorstore as a retriever\n",
    "        chain_type=\"stuff\",\n",
    "        return_source_documents=True, # including source documents in output\n",
    "        chain_type_kwargs={'prompt': prompt} # customizing the prompt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a64185b1-b0ce-4e3f-ac05-a93a294c4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prettifying the response\n",
    "def get_response(query, chain, **kwargs):\n",
    "    # Getting response from chain\n",
    "    response = chain.invoke({'query': query, **kwargs})\n",
    "    \n",
    "    # Wrapping the text for better output in Jupyter Notebook\n",
    "    wrapped_text = textwrap.fill(response['result'], width=100)\n",
    "    print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab08cf-efbb-41e0-8153-6bd787b4d5c1",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d90e0d-0ceb-416d-9ec2-6fd984edac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97270ade-5882-4086-944a-e969155dac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = OllamaLLM(model=\"orca-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18b0c917-42d4-4171-84d2-e77854aa063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"llama3.2\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aac8759-7a00-4cc5-9907-b6620a8f2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = OllamaLLM(model=\"mistral\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9af3c235-db6b-4b9f-8bb8-acc05133cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed = load_embedding_model(model_path=\"all-MiniLM-L6-v2\")\n",
    "embed = load_embedding_model(model_path=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "# embed = load_embedding_model(model_path=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3df3a966-325b-4797-aeb8-d3311713250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    \"./docs/rodtep_guidelines-output.pdf\",\n",
    "    \"./docs/Drawback-Rates.pdf\",\n",
    "    \"./docs/furniture_tv.pdf\",\n",
    "]\n",
    "docs = load_pdfs(file_paths=file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0a690d9-0e00-4ec8-a0a7-870e5dcb351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = split_docs(documents=docs)\n",
    "\n",
    "# creating vectorstore\n",
    "vectorstore = create_embeddings(documents, embed)\n",
    "\n",
    "# converting vectorstore to a retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54e65b3a-e680-4aee-aaf1-9bea42856f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the prompt from the template which we created before\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "### System:\n",
    "You are an respectful and honest assistant. You have to answer the user's \\\n",
    "questions using only the context provided to you. If you don't know the answer, \\\n",
    "please think rationally and answer from your own knowledge base\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### User:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "\"\"\")\n",
    "\n",
    "# Creating the chain\n",
    "chain = load_qa_chain(retriever, llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f79bb9-fdce-4c8b-af39-026fbdd5582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response(\"Explain the Kaplanâ€“Meier Survival Curve\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ef102-4d6c-437a-bce3-b952e4380156",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response(\"Explain the RDOTEP Guidelines\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d655825-266c-4ba8-9105-1fe41eac3012",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response(\"What are some of the things I have to keep in mind while exporting electronics\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89037cc2-5b04-482e-babe-b302e7b2416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response(\"What if i want to export a apple iphone mobile to USA\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbf177-8869-4ad0-9f3e-d09d5725c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response(\"What if i want to export furniture\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d5fbd-811a-4486-93de-6ca5a89906e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response(\"Give me a checklist if i want to export furniture\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6187a844-3216-40f8-ab6b-f71ad7c753b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response(\"What are the rates for furniture?\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef7a195-e449-43ea-8027-a5d41e99ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response(\"What are the rates?\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9d8420f-cb7e-474d-b549-6b57b773db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the data in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"Tariff Items\": [\n",
      "    {\n",
      "      \"Description of goods\": \"Perfumes and toilet waters\",\n",
      "      \"Unit\": \"3303\",\n",
      "      \"Drawback\": \"1.3%\",\n",
      "      \"Rate\": \"1.3%\",\n",
      "      \"Drawback cap per unit\": \"in Rs. (â‚¹)\",\n",
      "      \"Free on board value\": \"3303\"\n",
      "    },\n",
      "    {\n",
      "      \"Description of goods\": \"Preparations for use on the hair\",\n",
      "      \"Unit\": \"3305\",\n",
      "      \"Drawback\": \"1.3%\",\n",
      "      \"Rate\": \"1.3%\",\n",
      "      \"Drawback cap per unit\": \"in Rs. (â‚¹)\",\n",
      "      \"Free on board value\": \"3305\"\n",
      "    },\n",
      "    {\n",
      "      \"Description of goods\": \"Preparations for oral or dental hygiene, including denture fixative pastes and powders\",\n",
      "      \"Unit\": \"3306\",\n",
      "      \"Drawback\": \"1.3%\",\n",
      "      \"Rate\": \"1.3%\",\n",
      "      \"Drawback cap per unit\": \"in Rs. (â‚¹)\",\n",
      "      \"Free on board value\": \"3306\"\n",
      "    },\n",
      "    {\n",
      "      \"Description of goods\": \"Pre-shave, shaving or after-shave preparations, personal deodorants, bath preparations, depilatories and other perfumery, cosmetic or toilet preparations\",\n",
      "      \"Unit\": \"3307\",\n",
      "      \"Drawback\": \"1.3%\",\n",
      "      \"Rate\": \"1.3%\",\n",
      "      \"Drawback cap per unit\": \"in Rs. (â‚¹)\",\n",
      "      \"Free on board value\": \"3307\"\n",
      "    },\n",
      "    {\n",
      "      \"Description of goods\": \"Apparatus based on the use of X-rays or of alpha, beta or gamma radiations\",\n",
      "      \"Unit\": \"9022\",\n",
      "      \"Drawback\": \"1.3%\",\n",
      "      \"Rate\": \"1.3%\",\n",
      "      \"Drawback cap per unit\": \"in Rs. (â‚¹)\",\n",
      "      \"Free on board value\": \"9022\"\n",
      "    },\n",
      "    {\n",
      "      \"Description of goods\": \"Instruments, apparatus and models, designed for demonstrational purposes\",\n",
      "      \"Unit\": \"9023\",\n",
      "      \"Drawback\": \"1.3%\",\n",
      "      \"Rate\": \"1.3%\",\n",
      "      \"Drawback cap per unit\": \"in Rs. (â‚¹)\",\n",
      "      \"Free on board value\": \"9023\"\n",
      "    },\n",
      "    {\n",
      "      \"Description of goods\": \"Machines and appliances for testing the hardness, strength, compressibility, elasticity or other mechanical properties of materials\",\n",
      "      \"Unit\": \"9024\",\n",
      "      \"Drawback\": \"1.3%\",\n",
      "      \"Rate\": \"1.3%\",\n",
      "      \"Drawback cap per unit\": \"in Rs. (â‚¹)\",\n",
      "      \"Free on board value\": \"9024\"\n",
      "    },\n",
      "    {\n",
      "      \"Description of goods\": \"Hydrometers and similar floating instruments, thermometers, pyrometers\",\n",
      "      \"Unit\": \"9025\",\n",
      "      \"Drawback\": \"1.3%\",\n",
      "      \"Rate\": \"1.3%\",\n",
      "      \"Drawback cap per unit\": \"in Rs. (â‚¹)\",\n",
      "      \"Free on board value\": \"9025\"\n",
      "    },\n",
      "    {\n",
      "      \"Description of goods\": \"Molluscs, whether in shell or not, live, fresh, chilled, frozen, dried, salted or in brine\",\n",
      "      \"Unit\": \"0307\",\n",
      "      \"Drawback\": \"2.9%\",\n",
      "      \"Rate\": \"24.2%\",\n",
      "      \"Drawback cap per unit\": \"Kg\",\n",
      "      \"Free on board value\": \"030701\"\n",
      "    },\n",
      "    {\n",
      "      \"Description of goods\": \"Aquatic invertebrates other than crustaceans and molluscs, live, fresh, chilled, frozen, dried, salted or in brine\",\n",
      "      \"Unit\": \"0308\",\n",
      "      \"Drawback\": \"2.9%\",\n",
      "      \"Rate\": \"24.2%\",\n",
      "      \"Drawback cap per unit\": \"Kg\",\n",
      "      \"Free on board value\": \"030801\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Note that the data is in JSON format, with each tariff item as a separate object within an array of tariff items. The keys for each object are:\n",
      "\n",
      "* `Description of goods`\n",
      "* `Unit`\n",
      "* `Drawback`\n",
      "* `Rate`\n",
      "* `Drawback cap per unit` (in Rs. (â‚¹))\n",
      "* `Free on board value`\n",
      "\n",
      "The values for each key are the corresponding data from the original table.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"What are the rates?\", chain, system=\"Return the data only in json which can be directly parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "658d498e-47b4-4dcf-b7cc-0d640c92f6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"rates\": {\"3303\": \"1.3%\", \"3304\": \"1.3%\", \"3305\": \"1.3%\", \"3306\": \"1.3%\", \"3307\": \"1.3%\", \"330701\": \"1.3%\"}}\n"
     ]
    }
   ],
   "source": [
    "# Creating the prompt from the template which we created before\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "### System:\n",
    "Return the data only in json which can be directly parsed\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### User:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "\"\"\")\n",
    "\n",
    "# Creating the chain\n",
    "chain = load_qa_chain(retriever, llm, prompt)\n",
    "\n",
    "get_response(\"What are the rates?\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51faac56-f983-47f9-b6f1-3fe7ff9e339c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
